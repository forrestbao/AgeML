{"cells":[{"cell_type":"markdown","source":"# Training data preparation\nIn this project, we have human subject data sampled annually. The human subjects are identified uniquelly via the variable `hhidpn` and the year via `wave`. \n* Features: \n    * categorical: `race`, \n    * semi-categorical/numerical: `educ`, `cohort`, `female` (binary)\n    * continous/numerical: `age`, `activity`, `freqpray`, `mwi`, `assets`, `income`, `social` (?), `physd` (?), `formal`, `informal`, `depress`, `memoryp` (binary), `everyday`, `majordisc`, `cumulative`,  \n    * not in use: `wave` (year), `dead` (binary), \n* Targets: `recall`, `seven`, `bwcount`. they are added into `cogtot`. for most people, they all drop along time as our brain degrades. \n\nSome variables are not time-variant: `female`, `race`, `educ`, `cohort`. \n","metadata":{"tags":[],"cell_id":"41d630ef7c244023811cfa9b588688a3","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"numerical_features = [\"female\", \"age\", \"educ\", \"cohort\", \"activity\", \n    \"freqpray\", \"mwi\", \"assets\", \"income\", \"social\", \"physd\", \"formal\", \n    \"informal\", \"depress\", \"memoryp\", \"everyday\", \"majordisc\", \"cumulative\"]\n# try to exclude: everyday, majordisc, cumulative \ncategorical_features = [\"race\"]\nfeature_columns = numerical_features + categorical_features\ntarget_columns = [\"recall\", \"seven\", \"bwcount\"]\nidentifier_columns = [\"hhidpn\", \"wave\", \"dead\"]\nkeep_columns = feature_columns + target_columns +  identifier_columns","metadata":{"tags":[],"cell_id":"d743b4a197e64d1a99655e538c844288","source_hash":"295c0259","execution_start":1671132169625,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# What we want\nWe want to predict what factors significantly impact the cognitive functioning over time. How do you quantify the significance...It can be measured on the change of a dependent variable. \n\n# Data filtering \n* Only rows with `dead==0` and `age>0` are used. This reduces total number of rows from 50k to 20k. \n* Drop any row where targets are strings or NaN. \n* Drop any subject's data is the number of wave is below 2. \n\n# ideas for the future\n1. Transfer/multi-task learning w.r.t. to group identifiers, e.g., race. \n\n","metadata":{"tags":[],"cell_id":"cc2d7d722d204ecfab17876328863d46","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Loading the data","metadata":{"tags":[],"cell_id":"b2b740affdad47c090931c979ffadbf3","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"import pandas\nimport numpy\nimport tqdm\nimport pickle ","metadata":{"tags":[],"cell_id":"ebf8c40d4bd04e3c9ef4f96a58d397f2","source_hash":"78d9c29","execution_start":1671215134365,"execution_millis":75,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pandas.read_csv(\"ML_social.csv\")","metadata":{"tags":[],"cell_id":"89bca19af55d4262baf98b1062becd1b","source_hash":"519a3545","owner_user_id":"145f3a66-d802-4b09-b52b-1e21c3f2d596","execution_start":1671215134519,"execution_millis":2531,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py-core/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3139: DtypeWarning: Columns (5,24,28,29,30,31,32,33,34,61,62) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df.columns","metadata":{"tags":[],"cell_id":"308d019bcf66451cadeeed40911974bf","source_hash":"25d43fa0","execution_start":1671215137170,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"Index(['hhidpn', 'wave', 'race', 'female', 'educ', 'cohort', 'recall', 'seven',\n       'bwcount', 'age', 'assets', 'income', 'activity', 'formal', 'informal',\n       'hbp', 'diab', 'lung', 'angina', 'myocard', 'heartfail', 'stroke',\n       'arthritis', 'cogtot', 'mar', 'depress', 'newwork', 'dead', 'lb036a',\n       'lb036b', 'lb036c', 'lb036d', 'lb036e', 'lb036f', 'lb036g', 'freqpray',\n       'attribution', 'lb030a', 'lb030b', 'lb030c', 'lb030d', 'lb030e',\n       'lb030f', 'lb030g', 'lb021b', 'lb021d', 'lb021f', 'lb021h', 'd1', 'd2',\n       'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'ltact_i', 'mddact_i', 'vigact_i',\n       'mwi', 'obese', 'memoryp', 'adrd', 'physd', 'social', 'everyday',\n       'disca', 'discb', 'discc', 'discd', 'disce', 'discf', 'majordisc',\n       'cumulative'],\n      dtype='object')"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df['age'].mean()","metadata":{"tags":[],"cell_id":"353a4c9a6f42466190f34cff08edaf4f","source_hash":"2008e75e","execution_start":1671215494176,"execution_millis":13,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"67.20632366520015"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# print (target_columns)\n# for user in df['hhidpn'].unique():\n#     user_df = df[df['hhidpn']==user]\n#     if user_df[target_columns].isna().any(axis=1).any():\n#         print (user_df)\n#         print (user_df[target_columns].isna().any(axis=1).index)\n#         print (user_df[target_columns].isna())\n#         print (user_df[target_columns].isna().any(axis=1))\n#         na_judge = user_df[target_columns].isna().any(axis=1)\n#         print (na_judge[na_judge].index)\n#         print (user_df.dropna(subset=target_columns))\n#         break ","metadata":{"tags":[],"cell_id":"4b32dcb5829b42d6994dbcb5da15f009","source_hash":"3d364597","is_code_hidden":false,"execution_start":1671132172483,"execution_millis":11,"is_output_hidden":true,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Filtering columns \nWe will only use columns below from the CSV file. ","metadata":{"tags":[],"cell_id":"808fbf0fd38f417c90bf6ca63186d3a8","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"df = df[keep_columns]\nprint (\"Columns kept:\", df.columns)","metadata":{"tags":[],"cell_id":"fd6fb7ac705543f0b6e18d9e414a3076","source_hash":"723aeef5","execution_start":1671132172547,"execution_millis":107,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Columns kept: Index(['female', 'age', 'educ', 'cohort', 'activity', 'freqpray', 'mwi',\n       'assets', 'income', 'social', 'physd', 'formal', 'informal', 'depress',\n       'memoryp', 'everyday', 'majordisc', 'cumulative', 'race', 'recall',\n       'seven', 'bwcount', 'hhidpn', 'wave', 'dead'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Dropping rows, round 1: based on target Nan and `dead` and `age`","metadata":{"tags":[],"cell_id":"d256961fa87744339b6a86f7cb8f140b","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"print (f\"Original number of rows: {len(df)}, and subjects: {len(df['hhidpn'].unique())}\") \ndf=df.dropna(subset=target_columns)\nprint (f\"After dropping rows that has NaN in target columns, \\\n        \\n\\t in remaining data, \\\n        number of rows:  {len(df)}, and subjects: {len(df['hhidpn'].unique())} \")\ndf = df[df['dead']==0]\nprint (f\"After dropping rows where dead column is 0,  \\n\\t in remaining data, \\\n        number of rows:  {len(df)}, and subjects: {len(df['hhidpn'].unique())} \")\ndf = df[df['age']>0]\nprint (f\"After dropping rows where age column is not a number: \\n\\t in remaining data, \\\n        number of rows:  {len(df)}, and subjects: {len(df['hhidpn'].unique())} \")\n","metadata":{"tags":[],"cell_id":"064ea772cce4452ebe84cba67abc020b","source_hash":"a577d00","execution_start":1671132172653,"execution_millis":164,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Original number of rows: 407260, and subjects: 50971\nAfter dropping rows that has NaN in target columns,         \n\t in remaining data,         number of rows:  138658, and subjects: 30116 \nAfter dropping rows where dead column is 0,  \n\t in remaining data,         number of rows:  127029, and subjects: 29965 \nAfter dropping rows where age column is not a number: \n\t in remaining data,         number of rows:  127029, and subjects: 29965 \n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Remove `.*` strings and numericalize all data\nReplace `.s`, `.r`, `.d` and `.m` to `numpy.nan`. ","metadata":{"tags":[],"cell_id":"cfb3e65f019c40249b034748d34c55bd","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Test `.*` strings","metadata":{"tags":[],"cell_id":"7991129fddec4de3bbee6d36ee279496","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# .s and .m examples \ndf['depress'].iloc[3770:3780]","metadata":{"tags":[],"cell_id":"3dfaae2982174a468772cdaf7cb6e1f7","source_hash":"a1b3f330","is_code_hidden":true,"execution_start":1671132172826,"execution_millis":6,"is_output_hidden":true,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"8676    0\n8677    0\n8679    0\n8680    0\n8681    0\n8682    0\n8683    0\n8687    0\n8688    0\n8695    0\nName: depress, dtype: object"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# .r example \ndf['memoryp'].iloc[13130:13140]","metadata":{"tags":[],"cell_id":"3e156ca547c74a23b9ad757ed83cbe5c","source_hash":"866d7678","is_code_hidden":false,"execution_start":1671132172837,"execution_millis":41,"is_output_hidden":true,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"30322    NaN\n30323    NaN\n30324    NaN\n30325    NaN\n30326    NaN\n30328      0\n30329      0\n30330    NaN\n30331    NaN\n30332    NaN\nName: memoryp, dtype: object"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# .x example \ndf['recall'].iloc[5100:5110]","metadata":{"tags":[],"cell_id":"e6397292f3d74b3a971c8ed93e291a18","source_hash":"b8e27183","is_code_hidden":true,"execution_start":1671132172884,"execution_millis":4,"is_output_hidden":true,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"11492    16\n11504     6\n11505    11\n11506     6\n11513    10\n11514     6\n11515    10\n11516    10\n11550     7\n11551     6\nName: recall, dtype: object"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# .d example \ndf['memoryp'].iloc[31290:31300]","metadata":{"tags":[],"cell_id":"90a925cef54943429ffdbf3a45d46862","source_hash":"6317daa9","is_code_hidden":true,"execution_start":1671132172891,"execution_millis":5,"is_output_hidden":true,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"76624    NaN\n76625    NaN\n76626    NaN\n76628      0\n76629      0\n76630    NaN\n76631    NaN\n76632    NaN\n76633    NaN\n76634    NaN\nName: memoryp, dtype: object"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"#### Actually removing them and turning all columns to numeric ","metadata":{"tags":[],"cell_id":"101a9af84e07434c99d3d9ddc86684d1","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"for special_string in [\".s\", \".m\", \".r\", \".d\", \".x\"]:\n    df = df.replace(special_string, numpy.nan)\n\nfor column in df.columns: \n    # print (type(df_test[column].dtype))\n    if df[column].dtype == numpy.object_:\n        # print (column)\n        df[column] = pandas.to_numeric(df[column])\n\n# verify it works globally\n# print (df_test.dtypes)\n\n# verify that it really works locally \n# print (\"before\", df4['memoryp'].iloc[31295:31300])\n# print (\"After\", df_test['memoryp'].iloc[31295:31300])\n\n\n# Test code. Ensure no .s, .m, .r, .d any more. \n# for index, row in df.iterrows():\n#     for i in range(len(row)):\n#         if row.iloc[i]  == \".s\":\n#             print (row)\n#             break","metadata":{"tags":[],"cell_id":"777df1658e744b4894cac559aabcdff2","source_hash":"f11a6502","is_code_hidden":false,"execution_start":1671132172899,"execution_millis":649,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Dropping rows, round 2: `NaN` row introduced after replacing `.*` strings","metadata":{"tags":[],"cell_id":"8025c7859fee4d71bfe53168e0eb33ab","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"print (\"number of rows, before: \", len(df))\nprint (\"number of subjects, before: \", len(df['hhidpn'].unique()))\ndf=df.dropna(subset=target_columns)\nprint (\"number of rows, after: \", len(df))\nprint (\"number of subjects, after: \", len(df['hhidpn'].unique()))\n","metadata":{"tags":[],"cell_id":"a9a71e1e50114c5da263f0fd59c4f3a8","source_hash":"e2fa3a60","execution_start":1671132173579,"execution_millis":30,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"number of rows, before:  127029\nnumber of subjects, before:  29965\nnumber of rows, after:  123025\nnumber of subjects, after:  29648\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## Dropping rows, round 3: remove subjects with less than 2 waves. ","metadata":{"tags":[],"cell_id":"25a9e031e05345a58a06d0d8252aacdf","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"print (\"Original number of subjects:\", len(df['hhidpn'].unique()), \"Original number of rows:\", len(df) )\n\nokay_row, okay_subject, seq_length = 0, 0,  []  \n\nqualified_subject = []\nfor subjectID in tqdm.tqdm(df['hhidpn'].unique()):\n    subject_df = df[df['hhidpn']==subjectID]\n    if len(subject_df) > 1:\n        okay_subject += 1\n        okay_row += len(subject_df) \n        seq_length.append(len(subject_df) )\n        qualified_subject.append(int(subjectID)) \n\n        # debug \n        # if okay_subject> 10 :\n        #     break \n\ndf = df[df['hhidpn'].isin(qualified_subject)] \n\nprint (\"\\nNumber of okayed subjets:\", okay_subject, \"Number of okayed rows:\", okay_row, \"average length (years) of a subject:\",  sum(seq_length)/len(seq_length))\n","metadata":{"tags":[],"cell_id":"e202056a1ea24905a1fa53473b23ae4e","source_hash":"8d5b2d70","execution_start":1671132173612,"execution_millis":18186,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Original number of subjects: 29648 Original number of rows: 123025\n100%|██████████| 29648/29648 [00:18<00:00, 1635.34it/s]\nNumber of okayed subjets: 26178 Number of okayed rows: 119555 average length (years) of a subject: 4.567002826801131\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"df.dtypes","metadata":{"tags":[],"cell_id":"9c4662928681482ab85fdd71abd4fbbf","source_hash":"52430027","execution_start":1671136435227,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"female        float64\nage           float64\neduc          float64\ncohort        float64\nactivity      float64\nfreqpray      float64\nmwi           float64\nassets        float64\nincome        float64\nsocial        float64\nphysd         float64\nformal        float64\ninformal      float64\ndepress       float64\nmemoryp       float64\neveryday      float64\nmajordisc     float64\ncumulative    float64\nrace          float64\nrecall        float64\nseven         float64\nbwcount       float64\nhhidpn          int64\nwave            int64\ndead          float64\ndtype: object"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"## Filling NA","metadata":{"tags":[],"cell_id":"0fb9924c9f0d486a962ec27a72aceaa9","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# fill N/A\ndf = df.fillna(0.5)","metadata":{"tags":[],"cell_id":"3a1a6a4103f94d7dbf38de7f04d4bb80","source_hash":"26faee98","execution_start":1671132191797,"execution_millis":43,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Creating the X,Y pairs \n\nX or Y is a 1-D list of 2D numpy.ndarry, looks like this: \n```python\n[\n    [# subject 1 \n        [feature_1, feature_2, feature_3], # year 1 \n        [], # year 2\n        ...\n        [], # year M  \n    ], \n    [\n        [], # year 1 \n        [], # year 2\n        ...\n        [], # year M  \n    ], # subject 2\n    ...\n    [\n        [], # year 1 \n        [], # year 2\n        ...\n        [], # year M  \n    ], # subject N  \n]\n```\n","metadata":{"tags":[],"cell_id":"f0b0b47e199e45d8931d1e184ba2b1df","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"len(numerical_features)","metadata":{"tags":[],"cell_id":"aede46676faf47debc0ecb75c95f0237","source_hash":"56dcbfb6","execution_start":1671132191840,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"18"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import sklearn, sklearn.preprocessing \n\ndef pack_into_time_series(df, numerical_features, categorical_features, target_columns):\n    X, Y = [], [] # X and y are the training inputs and targets. \n    # X, Y = numpy.array([]), numpy.array([]) # X and y are the training inputs and targets. \n    # X or Y is a 1D list of 2D numpy arrays. X[subject] -> array[year][feature]\n\n    # one hot encoding for categorical features\n    one_hot_encoder = sklearn.preprocessing.OneHotEncoder(sparse=False)\n    categorical_transformed = one_hot_encoder.fit_transform(df[categorical_features].to_numpy()) \n    one_hot_encoded_feature_names = one_hot_encoder.get_feature_names_out(categorical_features)\n    ohe_df = pandas.DataFrame(categorical_transformed, \n                                columns=one_hot_encoded_feature_names, \n                                index = df.index) # without the index, concat misalin unless using ignore_index\n    feature_columns = numerical_features + one_hot_encoded_feature_names.tolist()\n    df = df.drop(categorical_features, axis=1)\n    df = pandas.concat([df, ohe_df], axis=1)\n      \n    # # Columns of type Object to float64 \n    # for a_numerical_feature in numerical_features: \n    #     if df[a_numerical_feature].dtype not in ['int', 'float']:\n    #         df[a_numerical_feature] = df[a_numerical_feature].astype(float)\n\n    # min-max scale for numerical features \n    feature_scaler = sklearn.preprocessing.MinMaxScaler()\n    df[numerical_features] = feature_scaler.fit_transform(df[numerical_features])\n\n    target_scaler = sklearn.preprocessing.MinMaxScaler()\n    df[target_columns] = feature_scaler.fit_transform(df[target_columns])\n\n    for subjectID in tqdm.tqdm(df['hhidpn'].unique()):\n        subject_df = df[df['hhidpn'] == subjectID]\n        subject_X, subject_Y = subject_df[feature_columns].to_numpy(), subject_df[target_columns].to_numpy()\n        X.append(subject_X)\n        Y.append(subject_Y)\n        # numpy.append(X, subject_X, axis=0)\n        # numpy.append(Y, subject_Y, axis=0)\n        # break \n\n    X, Y  = numpy.array(X), numpy.array(Y)\n\n    return X, Y\n\nX, Y  = pack_into_time_series(df, numerical_features, categorical_features, target_columns)\nprint (X.shape, Y.shape)\n\npickle.dump([X, Y], open(\"XY.pickle\", 'wb'))","metadata":{"tags":[],"cell_id":"6639650ced064879ac3075c9e49d5296","source_hash":"10f983c7","execution_start":1671132191841,"execution_millis":51514,"is_output_hidden":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"100%|██████████| 26178/26178 [00:50<00:00, 521.40it/s]\n/tmp/ipykernel_74/1321518648.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  X, Y  = numpy.array(X), numpy.array(Y)\n(26178,) (26178,)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=38ce621b-4696-4047-8b25-0501b493ce55' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"e400921b4f28428fbb26c3b35caf128f","deepnote_execution_queue":[]}}